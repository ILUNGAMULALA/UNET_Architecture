{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "In3cWT48sM9y"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add the path to the directory containing UNET.py (only if it is in a different directory)\n",
        "sys.path.append('/content/drive/MyDrive/')\n",
        "\n",
        "from tensorflow.python.keras.utils.version_utils import callbacks\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from glob import glob\n",
        "from sklearn.utils import shuffle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from UNET import build_unet # Or try: from .UNET import build_unet\n",
        "from metrics import dice_loss, dice_coef"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Global parameters \"\"\"\n",
        "\n",
        "H = 256\n",
        "W = 256\n",
        "\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n"
      ],
      "metadata": {
        "id": "KsXoKzj9J4_B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(path, split=0.2):\n",
        "    images = sorted(glob(os.path.join(path, \"images\", \"*.png\")))\n",
        "    masks = sorted(glob(os.path.join(path, \"masks\", \"*.png\")))\n",
        "    #print(images[0], masks[0])\n",
        "\n",
        "    split_size = int(len(images) * split)\n",
        "\n",
        "    train_x, valid_x = train_test_split(images, test_size=split_size, random_state=42)\n",
        "    train_y, valid_y = train_test_split(masks, test_size=split_size, random_state=42)\n",
        "\n",
        "    train_x, test_x = train_test_split(train_x, test_size=split_size, random_state=42)\n",
        "    train_y, test_y = train_test_split(train_y, test_size=split_size, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n"
      ],
      "metadata": {
        "id": "ClN-yh4_KAUC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x= x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(path):\n",
        "    path = path.decode()\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)  #(h,w)\n",
        "    x = cv2.resize(x, (W, H))  #(h,w)\n",
        "    x= x/255.0  #(h,w)\n",
        "    x= x.astype(np.float32)  #(h,w)\n",
        "    x = np.expand_dims(x, axis = -1)  #(h,w,1)\n",
        "\n",
        "    return x\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    def _parse(x, y):\n",
        "        x = read_image(x)\n",
        "        y = read_mask(y)\n",
        "        return x, y\n",
        "\n",
        "    x, y = tf.numpy_function(_parse, [x, y], [tf.float32, tf.float32])  # <-- Assign output\n",
        "\n",
        "    x.set_shape((H, W, 3))  # <-- Explicitly set the shape after assignment\n",
        "    y.set_shape((H, W, 1))\n",
        "\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "KetpTl8DKFS2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(X, Y, batch = 2):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.prefetch(10)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"Seeding\"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\"directory for storing files\"\"\"\n",
        "    create_dir(\"files\")\n",
        "\n",
        "    \"\"\"Hyperparameters\"\"\"\n",
        "    batch_size = 16\n",
        "    lr = 1e-4\n",
        "    num_epochs = 500\n",
        "    model_path = os.path.join(\"files\", \"model.h5\")\n",
        "    csv_path = os.path.join(\"files\", \"log.csv\")\n",
        "\n",
        "    \"\"\"Dataset\"\"\"\n",
        "    dataset_path = \"/content/drive/MyDrive/SegmentationDataset\"\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
        "\n",
        "    print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
        "    print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")\n",
        "    print(f\"Test: {len(test_x)} - {len(test_y)}\")\n",
        "\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch = batch_size)\n",
        "\n",
        "    #for x, y in train_dataset:\n",
        "    #    print(x.shape, y.shape)\n",
        "\n",
        "    \"\"\"Model\"\"\"\n",
        "    model = build_unet((H, W, 3))\n",
        "    model.compile(loss=dice_loss, optimizer = Adam(lr), metrics = [dice_coef])\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(model_path, verbose=1, save_best_only=True),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
        "        CSVLogger(csv_path),\n",
        "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False),\n",
        "    ]\n",
        "\n",
        "    model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=valid_dataset,\n",
        "        callbacks=callbacks\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGIMM_ADKLI1",
        "outputId": "8d91907c-1a41-49dc-dbb4-0c39cce241c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1840 - 1840\n",
            "Valid: 612 - 612\n",
            "Test: 612 - 612\n",
            "Epoch 1/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13s/step - dice_coef: 0.0788 - loss: 0.9212 \n",
            "Epoch 1: val_loss improved from inf to 0.95465, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2088s\u001b[0m 17s/step - dice_coef: 0.0791 - loss: 0.9209 - val_dice_coef: 0.0450 - val_loss: 0.9547 - learning_rate: 1.0000e-04\n",
            "Epoch 2/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.1854 - loss: 0.8146\n",
            "Epoch 2: val_loss did not improve from 0.95465\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 950ms/step - dice_coef: 0.1856 - loss: 0.8144 - val_dice_coef: 0.0240 - val_loss: 0.9759 - learning_rate: 1.0000e-04\n",
            "Epoch 3/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843ms/step - dice_coef: 0.2447 - loss: 0.7553\n",
            "Epoch 3: val_loss improved from 0.95465 to 0.94245, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - dice_coef: 0.2448 - loss: 0.7552 - val_dice_coef: 0.0571 - val_loss: 0.9424 - learning_rate: 1.0000e-04\n",
            "Epoch 4/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.3107 - loss: 0.6893\n",
            "Epoch 4: val_loss improved from 0.94245 to 0.89660, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 979ms/step - dice_coef: 0.3108 - loss: 0.6892 - val_dice_coef: 0.1021 - val_loss: 0.8966 - learning_rate: 1.0000e-04\n",
            "Epoch 5/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - dice_coef: 0.3844 - loss: 0.6156\n",
            "Epoch 5: val_loss improved from 0.89660 to 0.70645, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 1s/step - dice_coef: 0.3845 - loss: 0.6155 - val_dice_coef: 0.2937 - val_loss: 0.7064 - learning_rate: 1.0000e-04\n",
            "Epoch 6/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.4588 - loss: 0.5412\n",
            "Epoch 6: val_loss improved from 0.70645 to 0.55169, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 965ms/step - dice_coef: 0.4589 - loss: 0.5411 - val_dice_coef: 0.4482 - val_loss: 0.5517 - learning_rate: 1.0000e-04\n",
            "Epoch 7/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.5291 - loss: 0.4709\n",
            "Epoch 7: val_loss improved from 0.55169 to 0.51316, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - dice_coef: 0.5291 - loss: 0.4709 - val_dice_coef: 0.4877 - val_loss: 0.5132 - learning_rate: 1.0000e-04\n",
            "Epoch 8/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.5854 - loss: 0.4146\n",
            "Epoch 8: val_loss improved from 0.51316 to 0.48033, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - dice_coef: 0.5854 - loss: 0.4146 - val_dice_coef: 0.5183 - val_loss: 0.4803 - learning_rate: 1.0000e-04\n",
            "Epoch 9/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.6383 - loss: 0.3617\n",
            "Epoch 9: val_loss did not improve from 0.48033\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 952ms/step - dice_coef: 0.6383 - loss: 0.3617 - val_dice_coef: 0.5009 - val_loss: 0.4973 - learning_rate: 1.0000e-04\n",
            "Epoch 10/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.6682 - loss: 0.3318\n",
            "Epoch 10: val_loss improved from 0.48033 to 0.41956, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - dice_coef: 0.6682 - loss: 0.3318 - val_dice_coef: 0.5807 - val_loss: 0.4196 - learning_rate: 1.0000e-04\n",
            "Epoch 11/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - dice_coef: 0.7065 - loss: 0.2935\n",
            "Epoch 11: val_loss improved from 0.41956 to 0.37359, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 964ms/step - dice_coef: 0.7065 - loss: 0.2935 - val_dice_coef: 0.6255 - val_loss: 0.3736 - learning_rate: 1.0000e-04\n",
            "Epoch 12/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - dice_coef: 0.7359 - loss: 0.2641\n",
            "Epoch 12: val_loss improved from 0.37359 to 0.32234, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 959ms/step - dice_coef: 0.7360 - loss: 0.2640 - val_dice_coef: 0.6766 - val_loss: 0.3223 - learning_rate: 1.0000e-04\n",
            "Epoch 13/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - dice_coef: 0.7648 - loss: 0.2352\n",
            "Epoch 13: val_loss did not improve from 0.32234\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 947ms/step - dice_coef: 0.7648 - loss: 0.2352 - val_dice_coef: 0.6499 - val_loss: 0.3437 - learning_rate: 1.0000e-04\n",
            "Epoch 14/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.7889 - loss: 0.2111\n",
            "Epoch 14: val_loss improved from 0.32234 to 0.30500, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 965ms/step - dice_coef: 0.7889 - loss: 0.2111 - val_dice_coef: 0.6898 - val_loss: 0.3050 - learning_rate: 1.0000e-04\n",
            "Epoch 15/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.8065 - loss: 0.1935\n",
            "Epoch 15: val_loss improved from 0.30500 to 0.26403, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 964ms/step - dice_coef: 0.8065 - loss: 0.1935 - val_dice_coef: 0.7329 - val_loss: 0.2640 - learning_rate: 1.0000e-04\n",
            "Epoch 16/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.8311 - loss: 0.1689\n",
            "Epoch 16: val_loss did not improve from 0.26403\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 953ms/step - dice_coef: 0.8310 - loss: 0.1690 - val_dice_coef: 0.6640 - val_loss: 0.3296 - learning_rate: 1.0000e-04\n",
            "Epoch 17/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.8374 - loss: 0.1626\n",
            "Epoch 17: val_loss did not improve from 0.26403\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 953ms/step - dice_coef: 0.8373 - loss: 0.1627 - val_dice_coef: 0.7031 - val_loss: 0.2966 - learning_rate: 1.0000e-04\n",
            "Epoch 18/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.8437 - loss: 0.1563\n",
            "Epoch 18: val_loss improved from 0.26403 to 0.26237, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 1s/step - dice_coef: 0.8437 - loss: 0.1563 - val_dice_coef: 0.7363 - val_loss: 0.2624 - learning_rate: 1.0000e-04\n",
            "Epoch 19/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - dice_coef: 0.8489 - loss: 0.1511\n",
            "Epoch 19: val_loss improved from 0.26237 to 0.23588, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 980ms/step - dice_coef: 0.8490 - loss: 0.1510 - val_dice_coef: 0.7624 - val_loss: 0.2359 - learning_rate: 1.0000e-04\n",
            "Epoch 20/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.8708 - loss: 0.1292\n",
            "Epoch 20: val_loss improved from 0.23588 to 0.22011, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 967ms/step - dice_coef: 0.8708 - loss: 0.1292 - val_dice_coef: 0.7787 - val_loss: 0.2201 - learning_rate: 1.0000e-04\n",
            "Epoch 21/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841ms/step - dice_coef: 0.8759 - loss: 0.1241\n",
            "Epoch 21: val_loss did not improve from 0.22011\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 948ms/step - dice_coef: 0.8759 - loss: 0.1241 - val_dice_coef: 0.7714 - val_loss: 0.2245 - learning_rate: 1.0000e-04\n",
            "Epoch 22/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - dice_coef: 0.8809 - loss: 0.1191\n",
            "Epoch 22: val_loss did not improve from 0.22011\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - dice_coef: 0.8809 - loss: 0.1191 - val_dice_coef: 0.7778 - val_loss: 0.2225 - learning_rate: 1.0000e-04\n",
            "Epoch 23/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - dice_coef: 0.8878 - loss: 0.1122\n",
            "Epoch 23: val_loss did not improve from 0.22011\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 955ms/step - dice_coef: 0.8878 - loss: 0.1122 - val_dice_coef: 0.7709 - val_loss: 0.2302 - learning_rate: 1.0000e-04\n",
            "Epoch 24/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - dice_coef: 0.8909 - loss: 0.1091\n",
            "Epoch 24: val_loss did not improve from 0.22011\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - dice_coef: 0.8909 - loss: 0.1091 - val_dice_coef: 0.7691 - val_loss: 0.2299 - learning_rate: 1.0000e-04\n",
            "Epoch 25/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - dice_coef: 0.8920 - loss: 0.1080\n",
            "Epoch 25: val_loss did not improve from 0.22011\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 953ms/step - dice_coef: 0.8920 - loss: 0.1080 - val_dice_coef: 0.7642 - val_loss: 0.2343 - learning_rate: 1.0000e-04\n",
            "Epoch 26/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - dice_coef: 0.8950 - loss: 0.1050\n",
            "Epoch 26: val_loss improved from 0.22011 to 0.18854, saving model to files/model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 1s/step - dice_coef: 0.8951 - loss: 0.1049 - val_dice_coef: 0.8097 - val_loss: 0.1885 - learning_rate: 1.0000e-05\n",
            "Epoch 27/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.9078 - loss: 0.0922\n",
            "Epoch 27: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 948ms/step - dice_coef: 0.9078 - loss: 0.0922 - val_dice_coef: 0.8076 - val_loss: 0.1908 - learning_rate: 1.0000e-05\n",
            "Epoch 28/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840ms/step - dice_coef: 0.9117 - loss: 0.0883\n",
            "Epoch 28: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 946ms/step - dice_coef: 0.9117 - loss: 0.0883 - val_dice_coef: 0.8079 - val_loss: 0.1908 - learning_rate: 1.0000e-05\n",
            "Epoch 29/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.9140 - loss: 0.0860\n",
            "Epoch 29: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 952ms/step - dice_coef: 0.9140 - loss: 0.0860 - val_dice_coef: 0.8081 - val_loss: 0.1907 - learning_rate: 1.0000e-05\n",
            "Epoch 30/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.9159 - loss: 0.0841\n",
            "Epoch 30: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 950ms/step - dice_coef: 0.9159 - loss: 0.0841 - val_dice_coef: 0.8071 - val_loss: 0.1918 - learning_rate: 1.0000e-05\n",
            "Epoch 31/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839ms/step - dice_coef: 0.9175 - loss: 0.0825\n",
            "Epoch 31: val_loss did not improve from 0.18854\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 1s/step - dice_coef: 0.9175 - loss: 0.0825 - val_dice_coef: 0.8067 - val_loss: 0.1921 - learning_rate: 1.0000e-05\n",
            "Epoch 32/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.9191 - loss: 0.0809\n",
            "Epoch 32: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - dice_coef: 0.9191 - loss: 0.0809 - val_dice_coef: 0.8049 - val_loss: 0.1938 - learning_rate: 1.0000e-06\n",
            "Epoch 33/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.9193 - loss: 0.0807\n",
            "Epoch 33: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 952ms/step - dice_coef: 0.9192 - loss: 0.0808 - val_dice_coef: 0.8051 - val_loss: 0.1936 - learning_rate: 1.0000e-06\n",
            "Epoch 34/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846ms/step - dice_coef: 0.9195 - loss: 0.0805\n",
            "Epoch 34: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 953ms/step - dice_coef: 0.9195 - loss: 0.0805 - val_dice_coef: 0.8049 - val_loss: 0.1938 - learning_rate: 1.0000e-06\n",
            "Epoch 35/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.9197 - loss: 0.0803\n",
            "Epoch 35: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 948ms/step - dice_coef: 0.9197 - loss: 0.0803 - val_dice_coef: 0.8043 - val_loss: 0.1944 - learning_rate: 1.0000e-06\n",
            "Epoch 36/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839ms/step - dice_coef: 0.9199 - loss: 0.0801\n",
            "Epoch 36: val_loss did not improve from 0.18854\n",
            "\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 1s/step - dice_coef: 0.9199 - loss: 0.0801 - val_dice_coef: 0.8044 - val_loss: 0.1943 - learning_rate: 1.0000e-06\n",
            "Epoch 37/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.9202 - loss: 0.0798\n",
            "Epoch 37: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 948ms/step - dice_coef: 0.9202 - loss: 0.0798 - val_dice_coef: 0.8047 - val_loss: 0.1940 - learning_rate: 1.0000e-07\n",
            "Epoch 38/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.9203 - loss: 0.0797\n",
            "Epoch 38: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - dice_coef: 0.9203 - loss: 0.0797 - val_dice_coef: 0.8049 - val_loss: 0.1939 - learning_rate: 1.0000e-07\n",
            "Epoch 39/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.9203 - loss: 0.0797\n",
            "Epoch 39: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 1s/step - dice_coef: 0.9203 - loss: 0.0797 - val_dice_coef: 0.8050 - val_loss: 0.1938 - learning_rate: 1.0000e-07\n",
            "Epoch 40/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844ms/step - dice_coef: 0.9203 - loss: 0.0797\n",
            "Epoch 40: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - dice_coef: 0.9203 - loss: 0.0797 - val_dice_coef: 0.8050 - val_loss: 0.1937 - learning_rate: 1.0000e-07\n",
            "Epoch 41/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.9204 - loss: 0.0796\n",
            "Epoch 41: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 949ms/step - dice_coef: 0.9204 - loss: 0.0796 - val_dice_coef: 0.8051 - val_loss: 0.1937 - learning_rate: 1.0000e-07\n",
            "Epoch 42/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.9204 - loss: 0.0796\n",
            "Epoch 42: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 1s/step - dice_coef: 0.9204 - loss: 0.0796 - val_dice_coef: 0.8051 - val_loss: 0.1936 - learning_rate: 1.0000e-07\n",
            "Epoch 43/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.9204 - loss: 0.0796\n",
            "Epoch 43: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - dice_coef: 0.9204 - loss: 0.0796 - val_dice_coef: 0.8051 - val_loss: 0.1936 - learning_rate: 1.0000e-07\n",
            "Epoch 44/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842ms/step - dice_coef: 0.9205 - loss: 0.0795\n",
            "Epoch 44: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 1s/step - dice_coef: 0.9205 - loss: 0.0795 - val_dice_coef: 0.8052 - val_loss: 0.1936 - learning_rate: 1.0000e-07\n",
            "Epoch 45/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.9205 - loss: 0.0795\n",
            "Epoch 45: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 952ms/step - dice_coef: 0.9205 - loss: 0.0795 - val_dice_coef: 0.8052 - val_loss: 0.1936 - learning_rate: 1.0000e-07\n",
            "Epoch 46/500\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845ms/step - dice_coef: 0.9205 - loss: 0.0795\n",
            "Epoch 46: val_loss did not improve from 0.18854\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 1s/step - dice_coef: 0.9205 - loss: 0.0795 - val_dice_coef: 0.8052 - val_loss: 0.1936 - learning_rate: 1.0000e-07\n"
          ]
        }
      ]
    }
  ]
}